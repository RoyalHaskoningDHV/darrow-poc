{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make training and test data parquet files\n",
    "\n",
    "The InputData has to ultimately be of the form dict[str, pd.DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = Path(\"~/projects/darrow/darrow-poc/\")\n",
    "\n",
    "\n",
    "type_dict = {\n",
    "    'altenburg1': 'discharge', \n",
    "    'eschweiler': 'discharge',\n",
    "    'herzogenrath1': 'discharge',\n",
    "    'juelich': 'discharge',\n",
    "    'stah': 'discharge',\n",
    "    'middenroer': 'precip',\n",
    "    'urft': 'precip',\n",
    "    'evap': 'evap',\n",
    "}\n",
    "    \n",
    "\n",
    "def read_csv(file_path: PathLike) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[0:100, :].loc[:, \n",
    "        [\n",
    "            'TIME', \n",
    "            'discharge_altenburg1', \n",
    "            'discharge_eschweiler',\n",
    "            'discharge_herzogenrath1',\n",
    "            'discharge_juelich',\n",
    "            'discharge_stah',\n",
    "            'precip_middenroer',\n",
    "            'precip_urft',\n",
    "            'evap',\n",
    "         ]\n",
    "    ]\n",
    "    df.rename(columns={\n",
    "        'discharge_altenburg1': 'altenburg1', \n",
    "        'discharge_eschweiler': 'eschweiler',\n",
    "        'discharge_herzogenrath1': 'herzogenrath1',\n",
    "        'discharge_juelich': 'juelich',\n",
    "        'discharge_stah': 'stah',\n",
    "        'precip_middenroer': 'middenroer',\n",
    "        'precip_urft': 'urft',\n",
    "    }, inplace=True)\n",
    "    df = pd.melt(df, id_vars=['TIME'], value_vars=[c for c in df.columns if c != \"TIME\"])\n",
    "    df[\"TIME\"] = pd.to_datetime(df[\"TIME\"])\n",
    "    df.columns = [\"TIME\", \"ID\", \"VALUE\"]\n",
    "    df['TYPE'] = df['ID'].apply(lambda x: type_dict[x])\n",
    "    return df\n",
    "\n",
    "\n",
    "train = read_csv(BASE_DIR / \"tests/testing_data/train.csv\")\n",
    "test = read_csv(BASE_DIR / \"tests/testing_data/test.csv\")\n",
    "\n",
    "\n",
    "train.to_parquet(BASE_DIR / \"tests/testing_data/train.parquet\")\n",
    "test.to_parquet(BASE_DIR / \"tests/testing_data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>ID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00+00:00</td>\n",
       "      <td>altenburg1</td>\n",
       "      <td>33.22525</td>\n",
       "      <td>discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00+00:00</td>\n",
       "      <td>altenburg1</td>\n",
       "      <td>33.55875</td>\n",
       "      <td>discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00+00:00</td>\n",
       "      <td>altenburg1</td>\n",
       "      <td>33.59025</td>\n",
       "      <td>discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00+00:00</td>\n",
       "      <td>altenburg1</td>\n",
       "      <td>34.38775</td>\n",
       "      <td>discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00+00:00</td>\n",
       "      <td>altenburg1</td>\n",
       "      <td>35.03700</td>\n",
       "      <td>discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>2018-01-04 23:00:00+00:00</td>\n",
       "      <td>evap</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>evap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>2018-01-05 00:00:00+00:00</td>\n",
       "      <td>evap</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>evap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>2018-01-05 01:00:00+00:00</td>\n",
       "      <td>evap</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>evap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>2018-01-05 02:00:00+00:00</td>\n",
       "      <td>evap</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>evap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>2018-01-05 03:00:00+00:00</td>\n",
       "      <td>evap</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>evap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         TIME          ID     VALUE       TYPE\n",
       "0   2018-01-01 00:00:00+00:00  altenburg1  33.22525  discharge\n",
       "1   2018-01-01 01:00:00+00:00  altenburg1  33.55875  discharge\n",
       "2   2018-01-01 02:00:00+00:00  altenburg1  33.59025  discharge\n",
       "3   2018-01-01 03:00:00+00:00  altenburg1  34.38775  discharge\n",
       "4   2018-01-01 04:00:00+00:00  altenburg1  35.03700  discharge\n",
       "..                        ...         ...       ...        ...\n",
       "795 2018-01-04 23:00:00+00:00        evap   0.01000       evap\n",
       "796 2018-01-05 00:00:00+00:00        evap   0.01000       evap\n",
       "797 2018-01-05 01:00:00+00:00        evap   0.01000       evap\n",
       "798 2018-01-05 02:00:00+00:00        evap   0.01000       evap\n",
       "799 2018-01-05 03:00:00+00:00        evap   0.01000       evap\n",
       "\n",
       "[800 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(BASE_DIR / \"tests/testing_data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twinn_ml_interface.objectmodels.input_data import InputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discharge_altenburg1:disc':                            discharge_altenburg1:disc\n",
       " TIME                                                \n",
       " 2010-01-01 00:00:00+00:00                   13.32225\n",
       " 2010-01-01 01:00:00+00:00                   13.30750\n",
       " 2010-01-01 02:00:00+00:00                   13.20100\n",
       " 2010-01-01 03:00:00+00:00                   13.29650\n",
       " 2010-01-01 04:00:00+00:00                   13.19000\n",
       " ...                                              ...\n",
       " 2010-01-04 23:00:00+00:00                   12.64500\n",
       " 2010-01-05 00:00:00+00:00                   12.64500\n",
       " 2010-01-05 01:00:00+00:00                   12.64500\n",
       " 2010-01-05 02:00:00+00:00                   12.55600\n",
       " 2010-01-05 03:00:00+00:00                   12.50300\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'discharge_eschweiler:disc':                            discharge_eschweiler:disc\n",
       " TIME                                                \n",
       " 2010-01-01 00:00:00+00:00                    8.66275\n",
       " 2010-01-01 01:00:00+00:00                    8.44475\n",
       " 2010-01-01 02:00:00+00:00                    8.24225\n",
       " 2010-01-01 03:00:00+00:00                    8.00025\n",
       " 2010-01-01 04:00:00+00:00                    7.73225\n",
       " ...                                              ...\n",
       " 2010-01-04 23:00:00+00:00                    2.47125\n",
       " 2010-01-05 00:00:00+00:00                    2.45075\n",
       " 2010-01-05 01:00:00+00:00                    2.41800\n",
       " 2010-01-05 02:00:00+00:00                    2.39325\n",
       " 2010-01-05 03:00:00+00:00                    2.37150\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'discharge_herzogenrath1:disc':                            discharge_herzogenrath1:disc\n",
       " TIME                                                   \n",
       " 2010-01-01 00:00:00+00:00                       3.07500\n",
       " 2010-01-01 01:00:00+00:00                       3.00550\n",
       " 2010-01-01 02:00:00+00:00                       2.83425\n",
       " 2010-01-01 03:00:00+00:00                       2.80100\n",
       " 2010-01-01 04:00:00+00:00                       2.83425\n",
       " ...                                                 ...\n",
       " 2010-01-04 23:00:00+00:00                       1.48300\n",
       " 2010-01-05 00:00:00+00:00                       1.48300\n",
       " 2010-01-05 01:00:00+00:00                       1.45375\n",
       " 2010-01-05 02:00:00+00:00                       1.34800\n",
       " 2010-01-05 03:00:00+00:00                       1.25400\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'discharge_herzogenrath2:disc':                            discharge_herzogenrath2:disc\n",
       " TIME                                                   \n",
       " 2010-01-01 00:00:00+00:00                       0.35200\n",
       " 2010-01-01 01:00:00+00:00                       0.32525\n",
       " 2010-01-01 02:00:00+00:00                       0.31100\n",
       " 2010-01-01 03:00:00+00:00                       0.31100\n",
       " 2010-01-01 04:00:00+00:00                       0.28150\n",
       " ...                                                 ...\n",
       " 2010-01-04 23:00:00+00:00                       0.22550\n",
       " 2010-01-05 00:00:00+00:00                       0.23650\n",
       " 2010-01-05 01:00:00+00:00                       0.23200\n",
       " 2010-01-05 02:00:00+00:00                       0.22550\n",
       " 2010-01-05 03:00:00+00:00                       0.22975\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'discharge_juelich:disc':                            discharge_juelich:disc\n",
       " TIME                                             \n",
       " 2010-01-01 00:00:00+00:00                23.42600\n",
       " 2010-01-01 01:00:00+00:00                23.24600\n",
       " 2010-01-01 02:00:00+00:00                23.03075\n",
       " 2010-01-01 03:00:00+00:00                22.80475\n",
       " 2010-01-01 04:00:00+00:00                22.66800\n",
       " ...                                           ...\n",
       " 2010-01-04 23:00:00+00:00                15.88725\n",
       " 2010-01-05 00:00:00+00:00                15.88225\n",
       " 2010-01-05 01:00:00+00:00                15.89675\n",
       " 2010-01-05 02:00:00+00:00                15.80550\n",
       " 2010-01-05 03:00:00+00:00                15.70950\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'discharge_stah:disc':                            discharge_stah:disc\n",
       " TIME                                          \n",
       " 2010-01-01 00:00:00+00:00             33.62925\n",
       " 2010-01-01 01:00:00+00:00             33.52300\n",
       " 2010-01-01 02:00:00+00:00             33.31150\n",
       " 2010-01-01 03:00:00+00:00             32.99500\n",
       " 2010-01-01 04:00:00+00:00             32.68000\n",
       " ...                                        ...\n",
       " 2010-01-04 23:00:00+00:00             22.75300\n",
       " 2010-01-05 00:00:00+00:00             22.93200\n",
       " 2010-01-05 01:00:00+00:00             22.93200\n",
       " 2010-01-05 02:00:00+00:00             22.93200\n",
       " 2010-01-05 03:00:00+00:00             22.93200\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'evap:evap':                            evap:evap\n",
       " TIME                                \n",
       " 2010-01-01 00:00:00+00:00       0.00\n",
       " 2010-01-01 01:00:00+00:00       0.00\n",
       " 2010-01-01 02:00:00+00:00       0.00\n",
       " 2010-01-01 03:00:00+00:00       0.00\n",
       " 2010-01-01 04:00:00+00:00       0.00\n",
       " ...                              ...\n",
       " 2010-01-04 23:00:00+00:00       0.02\n",
       " 2010-01-05 00:00:00+00:00       0.02\n",
       " 2010-01-05 01:00:00+00:00       0.02\n",
       " 2010-01-05 02:00:00+00:00       0.02\n",
       " 2010-01-05 03:00:00+00:00       0.02\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'precip_middenroer:prec':                            precip_middenroer:prec\n",
       " TIME                                             \n",
       " 2010-01-01 00:00:00+00:00                0.000000\n",
       " 2010-01-01 01:00:00+00:00                0.004192\n",
       " 2010-01-01 02:00:00+00:00                0.000500\n",
       " 2010-01-01 03:00:00+00:00                0.000000\n",
       " 2010-01-01 04:00:00+00:00                0.000000\n",
       " ...                                           ...\n",
       " 2010-01-04 23:00:00+00:00                0.246385\n",
       " 2010-01-05 00:00:00+00:00                0.058442\n",
       " 2010-01-05 01:00:00+00:00                0.019000\n",
       " 2010-01-05 02:00:00+00:00                0.003942\n",
       " 2010-01-05 03:00:00+00:00                0.013615\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'precip_urft:prec':                            precip_urft:prec\n",
       " TIME                                       \n",
       " 2010-01-01 00:00:00+00:00          0.000000\n",
       " 2010-01-01 01:00:00+00:00          0.000000\n",
       " 2010-01-01 02:00:00+00:00          0.000000\n",
       " 2010-01-01 03:00:00+00:00          0.000238\n",
       " 2010-01-01 04:00:00+00:00          0.000000\n",
       " ...                                     ...\n",
       " 2010-01-04 23:00:00+00:00          0.003452\n",
       " 2010-01-05 00:00:00+00:00          0.058112\n",
       " 2010-01-05 01:00:00+00:00          0.192789\n",
       " 2010-01-05 02:00:00+00:00          0.010272\n",
       " 2010-01-05 03:00:00+00:00          0.002721\n",
       " \n",
       " [100 rows x 1 columns]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputData.from_long_df(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to define the following:\n",
    "\n",
    "1. Model class following the Protocol `ModelinterfaceV4`\n",
    "2. As an input to the `initialize` method, this class requires an object based on the `Configuration` Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from darrow_poc.models.modelinterface import POCAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twinn_ml_interface.objectmodels import ModelCategory, MetaDataLogger, Configuration\n",
    "\n",
    "sm = POCAnomaly(target = \"discharge:stah\")\n",
    "\n",
    "#sm.performance_value = 999\n",
    "#sm.model_category = ModelCategory.ANOMALY\n",
    "#sm.model_type_name = \"stah\"\n",
    "#sm.base_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConfigurationMock:\n",
    "    target_name = \"test:test\"\n",
    "\n",
    "    def get_units(*args, **kwargs):\n",
    "        return None\n",
    "    \n",
    "model = POCAnomaly.initialize(ConfigurationMock(), MetaDataLogger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method POCAnomaly.preprocess of <darrow_poc.models.modelinterface.POCAnomaly object at 0x7f30d38b3d90>>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtwinn_ml_interface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelInterfaceV4\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sm, ModelInterfaceV4)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from twinn_ml_interface.interface import ModelInterfaceV4\n",
    "\n",
    "assert isinstance(sm, ModelInterfaceV4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from azure.data.tables import TableServiceClient\n",
    "\n",
    "from sam_infra_helper.api import MLAPI\n",
    "from sam_infra_helper.azure import WorkspaceService\n",
    "from sam_infra_helper.data import DataService, LabelService\n",
    "from sam_infra_helper.executors.shared_code import CheckpointLogger, SafeLogger\n",
    "from sam_infra_helper.hierarchy import Hierarchy\n",
    "from sam_infra_helper.model import ModelService\n",
    "from sam_infra_helper.objectmodels import SemanticVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "Could not parse SQLAlchemy URL from string '...'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msam_infra_helper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msqlalchemy_connector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLalchemyConnector\n\u001b[1;32m      3\u001b[0m connection_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m db_connector \u001b[38;5;241m=\u001b[39m \u001b[43mSQLalchemyConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m ml_api \u001b[38;5;241m=\u001b[39m MLAPI(db_connector)\n",
      "File \u001b[0;32m~/projects/darrow/sam-infra-helper/sam_infra_helper/database/connectors/sqlalchemy_connector.py:32\u001b[0m, in \u001b[0;36mSQLalchemyConnector.__init__\u001b[0;34m(self, connection_string, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A connector for general connections to databases using sqlalchemy.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    connection_string (str): connection string to the database.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    **kwargs (dict[str, Any]): additional key word arguments.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_string \u001b[38;5;241m=\u001b[39m connection_string\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/darrow/sam-infra-helper/sam_infra_helper/database/connectors/sqlalchemy_connector.py:36\u001b[0m, in \u001b[0;36mSQLalchemyConnector.create_engine\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new database engine to make connections with.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     _engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine: Engine \u001b[38;5;241m=\u001b[39m _engine\u001b[38;5;241m.\u001b[39mexecution_options(isolation_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUTOCOMMIT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/projects/darrow/twinn-ml-example/venv/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py:375\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    369\u001b[0m         _warn_with_version(\n\u001b[1;32m    370\u001b[0m             messages[m],\n\u001b[1;32m    371\u001b[0m             versions[m],\n\u001b[1;32m    372\u001b[0m             version_warnings[m],\n\u001b[1;32m    373\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    374\u001b[0m         )\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/darrow/twinn-ml-example/venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py:514\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty_in_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# create url.URL object\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43m_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m u, plugins, kwargs \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_instantiate_plugins(kwargs)\n\u001b[1;32m    518\u001b[0m entrypoint \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_get_entrypoint()\n",
      "File \u001b[0;32m~/projects/darrow/twinn-ml-example/venv/lib/python3.10/site-packages/sqlalchemy/engine/url.py:738\u001b[0m, in \u001b[0;36mmake_url\u001b[0;34m(name_or_url)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given a string or unicode instance, produce a new URL instance.\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \n\u001b[1;32m    727\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_url, util\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m--> 738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name_or_url\n",
      "File \u001b[0;32m~/projects/darrow/twinn-ml-example/venv/lib/python3.10/site-packages/sqlalchemy/engine/url.py:799\u001b[0m, in \u001b[0;36m_parse_url\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m URL\u001b[38;5;241m.\u001b[39mcreate(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponents)\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mArgumentError(\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse SQLAlchemy URL from string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name\n\u001b[1;32m    801\u001b[0m     )\n",
      "\u001b[0;31mArgumentError\u001b[0m: Could not parse SQLAlchemy URL from string '...'"
     ]
    }
   ],
   "source": [
    "from sam_infra_helper.database.connectors.sqlalchemy_connector import SQLalchemyConnector\n",
    "\n",
    "connection_str_ml = f\"...\"  # Which connection string do I need here? Which DB to use?\n",
    "\n",
    "connector_ml = SQLalchemyConnector(connection_str_ml)\n",
    "\n",
    "ml_api = MLAPI(connector_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SemanticVersion(major=0, minor=1, patch=0, dev_version=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from twinn_ml_example._version import __version__\n",
    "\n",
    "semantic_version = SemanticVersion.from_string(__version__)\n",
    "semantic_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection_str_dqls = f\"...\"\n",
    "connector_dqls = SQLalchemyConnector(connection_str_dqls)\n",
    "\n",
    "label_api = DQLSAPI(connector_dqls)\n",
    "\n",
    "label_service = LabelService(label_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from sam_infra_helper.data import AvailabilityService\n",
    "\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url: str, credential: str | Dict[str, str] | AzureNamedKeyCredential | \n",
    "    AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "availability_service = AvailabilityService(blob_service_client)\n",
    "\n",
    "data_service = DataService(availability_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_container_client = ContainerClient(\n",
    "    account_url: str, container_name: str, credential: str | Dict[str, str] | \n",
    "    AzureNamedKeyCredential | AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "log_container_client = ContainerClient(\n",
    "    account_url: str, container_name: str, credential: str | Dict[str, str] | \n",
    "    AzureNamedKeyCredential | AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "credentials = None\n",
    "model_service = ModelService(model_container_client, log_container_client, credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "safe_logger = SafeLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_logger = CheckpointLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.data.tables import TableServiceClient\n",
    "\n",
    "connection_string = \\\n",
    "    \"DefaultEndpointsProtocol=https;AccountName=<my_account_name>;AccountKey=<my_account_key>;EndpointSuffix=core.windows.net\"\n",
    "mlsync_service = TableServiceClient.from_connection_string(conn_str=connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "\n",
    "blob_client = BlobClient(\n",
    "    account_url: str, container_name: str, blob_name: str, snapshot: str | \n",
    "    Dict[str, Any] | None = None, credential: str | Dict[str, str] | AzureNamedKeyCredential | \n",
    "    AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "hierarchies = HierarchyFromBlobTree(blob_client).get_hierarchies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace_service = WorkspaceService(\n",
    "    workspace_name: str,\n",
    "    subscription_id: str,\n",
    "    resource_group: str,\n",
    "    credentials: Any = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_executor = TrainExecutor(\n",
    "    ml_api = ml_api,\n",
    "    product_version = semantic_version,\n",
    "    label_service = label_service,\n",
    "    data_service = data_service,\n",
    "    model_service = model_service,\n",
    "    safe_logger = safe_logger,\n",
    "    checkpoint_logger = checkpoint_logger,\n",
    "    mlsync_service = mlsync_service,\n",
    "    hierarchies = hierarchies,\n",
    "    workspace_service = workspace_service,\n",
    "    model_dir = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing._ProtocolMeta"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "\n",
    "type(Protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(type(Protocol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing._ProtocolMeta"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import _ProtocolMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ProtocolMeta??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Protocol) is _ProtocolMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (darrow POC)",
   "language": "python",
   "name": "darrowpoc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
