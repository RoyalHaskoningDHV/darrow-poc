{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make training and test data parquet files\n",
    "\n",
    "The InputData has to ultimately be of the form dict[str, pd.DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = Path(\"~/projects/darrow/darrow-poc/\")\n",
    "\n",
    "\n",
    "type_dict = {\n",
    "    'altenburg1': 'discharge', \n",
    "    'eschweiler': 'discharge',\n",
    "    'herzogenrath1': 'discharge',\n",
    "    'juelich': 'discharge',\n",
    "    'stah': 'discharge',\n",
    "    'middenroer': 'precipitation',\n",
    "    'urft': 'precipitation',\n",
    "    'evap': 'evaporation',\n",
    "}\n",
    "    \n",
    "\n",
    "def read_csv(file_path: PathLike) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[0:100, :].loc[:, \n",
    "        [\n",
    "            'TIME', \n",
    "            'discharge_altenburg1', \n",
    "            'discharge_eschweiler',\n",
    "            'discharge_herzogenrath1',\n",
    "            'discharge_juelich',\n",
    "            'discharge_stah',\n",
    "            'precip_middenroer',\n",
    "            'precip_urft',\n",
    "            'evap',\n",
    "         ]\n",
    "    ]\n",
    "    df.rename(columns={\n",
    "        'discharge_altenburg1': 'altenburg1', \n",
    "        'discharge_eschweiler': 'eschweiler',\n",
    "        'discharge_herzogenrath1': 'herzogenrath1',\n",
    "        'discharge_juelich': 'juelich',\n",
    "        'discharge_stah': 'stah',\n",
    "        'precip_middenroer': 'middenroer',\n",
    "        'precip_urft': 'urft',\n",
    "    }, inplace=True)\n",
    "    df = pd.melt(df, id_vars=['TIME'], value_vars=[c for c in df.columns if c != \"TIME\"])\n",
    "    df[\"TIME\"] = pd.to_datetime(df[\"TIME\"])\n",
    "    df.columns = [\"TIME\", \"ID\", \"VALUE\"]\n",
    "    df['TYPE'] = df['ID'].apply(lambda x: type_dict[x])\n",
    "    return df\n",
    "\n",
    "\n",
    "train = read_csv(BASE_DIR / \"tests/testing_data/train.csv\")\n",
    "test = read_csv(BASE_DIR / \"tests/testing_data/test.csv\")\n",
    "\n",
    "\n",
    "train.to_parquet(BASE_DIR / \"tests/testing_data/train.parquet\")\n",
    "test.to_parquet(BASE_DIR / \"tests/testing_data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_parquet(BASE_DIR / \"tests/testing_data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twinn_ml_interface.input_data.input_data import InputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "InputData.from_long_df(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to define the following:\n",
    "\n",
    "1. Model class following the Protocol `ModelinterfaceV4`\n",
    "2. As an input to the `initialize` method, this class requires an object based on the `Configuration` Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from darrow_poc.models.poc import POCAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twinn_ml_interface.objectmodels import ModelCategory, MetaDataLogger, Configuration\n",
    "\n",
    "sm = POCAnomaly(target = \"stah:discharge\")\n",
    "\n",
    "#sm.performance_value = 999\n",
    "#sm.model_category = ModelCategory.ANOMALY\n",
    "#sm.model_type_name = \"stah\"\n",
    "#sm.base_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConfigurationMock:\n",
    "    target_name = \"stah:discharge\"\n",
    "\n",
    "    def get_units(*args, **kwargs):\n",
    "        return None\n",
    "    \n",
    "model = POCAnomaly.initialize(ConfigurationMock(), MetaDataLogger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twinn_ml_interface.interface import ModelInterfaceV4\n",
    "\n",
    "assert isinstance(sm, ModelInterfaceV4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from azure.data.tables import TableServiceClient\n",
    "\n",
    "from sam_infra_helper.api import MLAPI\n",
    "from sam_infra_helper.azure import WorkspaceService\n",
    "from sam_infra_helper.data import DataService, LabelService\n",
    "from sam_infra_helper.executors.shared_code import CheckpointLogger, SafeLogger\n",
    "from sam_infra_helper.hierarchy import Hierarchy\n",
    "from sam_infra_helper.model import ModelService\n",
    "from sam_infra_helper.objectmodels import SemanticVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sam_infra_helper.database.connectors.sqlalchemy_connector import SQLalchemyConnector\n",
    "\n",
    "connection_str_ml = f\"...\"  # Which connection string do I need here? Which DB to use?\n",
    "\n",
    "connector_ml = SQLalchemyConnector(connection_str_ml)\n",
    "\n",
    "ml_api = MLAPI(connector_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twinn_ml_example._version import __version__\n",
    "\n",
    "semantic_version = SemanticVersion.from_string(__version__)\n",
    "semantic_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection_str_dqls = f\"...\"\n",
    "connector_dqls = SQLalchemyConnector(connection_str_dqls)\n",
    "\n",
    "label_api = DQLSAPI(connector_dqls)\n",
    "\n",
    "label_service = LabelService(label_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from sam_infra_helper.data import AvailabilityService\n",
    "\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url: str, credential: str | Dict[str, str] | AzureNamedKeyCredential | \n",
    "    AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "availability_service = AvailabilityService(blob_service_client)\n",
    "\n",
    "data_service = DataService(availability_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_container_client = ContainerClient(\n",
    "    account_url: str, container_name: str, credential: str | Dict[str, str] | \n",
    "    AzureNamedKeyCredential | AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "log_container_client = ContainerClient(\n",
    "    account_url: str, container_name: str, credential: str | Dict[str, str] | \n",
    "    AzureNamedKeyCredential | AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "credentials = None\n",
    "model_service = ModelService(model_container_client, log_container_client, credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "safe_logger = SafeLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_logger = CheckpointLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.data.tables import TableServiceClient\n",
    "\n",
    "connection_string = \\\n",
    "    \"DefaultEndpointsProtocol=https;AccountName=<my_account_name>;AccountKey=<my_account_key>;EndpointSuffix=core.windows.net\"\n",
    "mlsync_service = TableServiceClient.from_connection_string(conn_str=connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "\n",
    "blob_client = BlobClient(\n",
    "    account_url: str, container_name: str, blob_name: str, snapshot: str | \n",
    "    Dict[str, Any] | None = None, credential: str | Dict[str, str] | AzureNamedKeyCredential | \n",
    "    AzureSasCredential | TokenCredential | None = None, **kwargs: Any\n",
    ")\n",
    "hierarchies = HierarchyFromBlobTree(blob_client).get_hierarchies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace_service = WorkspaceService(\n",
    "    workspace_name: str,\n",
    "    subscription_id: str,\n",
    "    resource_group: str,\n",
    "    credentials: Any = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_executor = TrainExecutor(\n",
    "    ml_api = ml_api,\n",
    "    product_version = semantic_version,\n",
    "    label_service = label_service,\n",
    "    data_service = data_service,\n",
    "    model_service = model_service,\n",
    "    safe_logger = safe_logger,\n",
    "    checkpoint_logger = checkpoint_logger,\n",
    "    mlsync_service = mlsync_service,\n",
    "    hierarchies = hierarchies,\n",
    "    workspace_service = workspace_service,\n",
    "    model_dir = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "\n",
    "type(Protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(type(Protocol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(Protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import _ProtocolMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ProtocolMeta??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(Protocol) is _ProtocolMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (darrowpoc)",
   "language": "python",
   "name": "darrowpoc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
